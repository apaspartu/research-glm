## Генеративна мовна модель на основі рекурентної нейронної мережі з механізмом довгої короткочасної пам'яті ##

Основна реалізація моделі знаходиться у файлі `model.py`.

Структура проекту:
- *corpus/raw* - набір текстів в форматі txt;
- *generate.py* - скрипт для генерації токенізованих по реченнях текстів із необроблених текстів;
- *dataset.py* - модуль для генерації тренувальних та тестових наборів даних з токенізованого корпусу текстів;
- *misc.py* - деякі необхідні елементи для структурування даних;
- *tools.py* - інструменти для перетворення необроблених символьних послідовностей в векторну форму, придатну для обробки моделлю;
- *funcs.py* - математичні та допоміжні функції необхідні для побудови моделі;
- *model.py* - реалізація моделі кодувальника-декодувальника на основі рекурентних нейронних мереж LSTM;
- *experiments.py* - приклад використання моделі для тренування та генерації послідовностей.

Щоб запустити проект потрібно виконати наступні кроки:
1. Клонувати репозиторій на локальний комп'ютер.
2. Виконати скрипт `python generate.py`. В результаті в папці *corpus* з'явиться папка *tokenized* з текстами, очищеними та поділеними на речення.
3. Відкрити файл скрипта *experiments.py*, налаштувати потрібні гіперпараметри, та запустити на виконання даний скрипт командою `python experiments.py`.

Під час тренування відображається номер епохи на якій перебуває модель та величина втрат досягнута моделлю на цій епосі. Після завершення
навчання модель згенерує вихідну послідовність за заданої вхідною. В залежності від вибраного режиму навчання, наприклад `LearningMode.WORD`, 
модель буде обробляти слова, фрази чи речення з набору даних.
